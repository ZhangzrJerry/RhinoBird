{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, time, os\n",
    "import numpy as np\n",
    "import paddle\n",
    "import pandas as pd\n",
    "import paddle.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from visualdl import LogWriter\n",
    "logwriter = LogWriter(logdir='./runs')\n",
    "# visualdl --logdir ./runs/ --host 0.0.0.0 --port 8040\n",
    "\n",
    "users_df = pd.read_csv('data/csv/users.csv')\n",
    "items_df = pd.read_csv('data/csv/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_scale = 64\n",
    "batch_size = 4096\n",
    "len_users = len(users_df)\n",
    "len_items = len(items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(paddle.io.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.w = len(data[0])\n",
    "        self.h = len(data)\n",
    "        pass\n",
    "    def __getitem__(self, idx):\n",
    "        w = idx % self.w\n",
    "        h = int(idx / self.h)\n",
    "        return np.append(w, h), self.data[w][h]\n",
    "    def __len__(self):\n",
    "        return self.w * self.h\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSSM(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(DSSM,self).__init__()\n",
    "        self.users_emb = nn.Embedding(len_users+1, emb_scale)\n",
    "        self.items_emb = nn.Embedding(len_items+1, emb_scale)\n",
    "        self.fc = nn.Linear(2 * emb_scale, 1)\n",
    "        # self.users_fc1 = nn.Linear(emb_scale, 512)\n",
    "        # self.users_fc2 = nn.Linear(512, 300)\n",
    "        # self.users_fc3 = nn.Linear(300, 300)\n",
    "        # self.users_fc4 = nn.Linear(300, 128)\n",
    "        # self.items_fc1 = nn.Linear(emb_scale, 512)\n",
    "        # self.items_fc2 = nn.Linear(512, 300)\n",
    "        # self.items_fc3 = nn.Linear(300, 300)\n",
    "        # self.items_fc4 = nn.Linear(300, 128)\n",
    "        pass\n",
    "    def forward(self, input):\n",
    "        # user tower\n",
    "        user = self.users_emb(input[:,0])\n",
    "        # user = self.users_fc1(user)\n",
    "        # user = nn.functional.relu(user)\n",
    "        # user = self.users_fc2(user)\n",
    "        # user = nn.functional.relu(user)\n",
    "        # user = self.users_fc3(user)\n",
    "        # user = nn.functional.relu(user)\n",
    "        # user = self.users_fc4(user)\n",
    "        # item tower\n",
    "        item = self.items_emb(input[:,1])\n",
    "        # item = self.items_fc1(item)\n",
    "        # item = nn.functional.relu(item)\n",
    "        # item = self.items_fc2(item)\n",
    "        # item = nn.functional.relu(item)\n",
    "        # item = self.items_fc3(item)\n",
    "        # item = nn.functional.relu(item)\n",
    "        # item = self.items_fc4(item)\n",
    "        # similarity\n",
    "        x = nn.functional.cosine_similarity(user, item, axis=1)\n",
    "        x = nn.functional.sigmoid(x)\n",
    "        return x\n",
    "    pass\n",
    "dssm = DSSM()\n",
    "optim = paddle.optimizer.Adam(parameters=dssm.parameters(), learning_rate=0.005)\n",
    "m = paddle.metric.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1258/1258 [03:10<00:00,  6.60it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'data/net/test/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\2023犀牛鸟中学科学人才培养计划\\Flask\\DSSM.ipynb 单元格 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     logwriter\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mtrain_acc\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39macc\u001b[39m.\u001b[39mnumpy(), step\u001b[39m=\u001b[39mbatch_id\u001b[39m+\u001b[39mepoch_id\u001b[39m*\u001b[39m(batch_size))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     logwriter\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mtrain_recall\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mm\u001b[39m.\u001b[39maccumulate(), step\u001b[39m=\u001b[39mbatch_id\u001b[39m+\u001b[39mepoch_id\u001b[39m*\u001b[39m(batch_size))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m file_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39mdata/net/test/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdata/net/test/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mnp\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(file_list), \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m paddle\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mDataLoader(Dataset(pickle\u001b[39m.\u001b[39mload(file)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                                      drop_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                                      batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                                      shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'data/net/test/'"
     ]
    }
   ],
   "source": [
    "train_loss_, train_acc_, eval_loss_, eval_acc_ = [], [], [], []\n",
    "\n",
    "for epoch_id in range(10):\n",
    "\n",
    "    train_loss, train_acc, eval_loss, eval_acc = [], [], [], []\n",
    "\n",
    "    file_list = os.listdir('data/net/train/')\n",
    "    file = open('data/net/train/'+np.random.choice(file_list), 'rb')\n",
    "    train_dataset = paddle.io.DataLoader(Dataset(pickle.load(file)),\n",
    "                                         drop_last=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "    file.close()    \n",
    "\n",
    "    dssm.train()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(tqdm(train_dataset)):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = dssm(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        optim.clear_grad()\n",
    "        train_loss.append(loss.numpy())\n",
    "        train_acc.append(acc.numpy())\n",
    "\n",
    "        logwriter.add_scalar(\"train_loss\", value=loss.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"train_acc\", value=acc.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"train_recall\", value=m.accumulate(), step=batch_id+epoch_id*(batch_size))\n",
    "\n",
    "    file_list = os.listdir('data/net/eval/')\n",
    "    file = open('data/net/eval/'+np.random.choice(file_list), 'rb')\n",
    "    train_dataset = paddle.io.DataLoader(Dataset(pickle.load(file)),\n",
    "                                         drop_last=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "    file.close() \n",
    "\n",
    "    dssm.eval()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(tqdm(train_dataset)):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = dssm(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "\n",
    "        logwriter.add_scalar(\"eval_loss\", value=loss.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"eval_acc\", value=acc.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"eval_recall\", value=m.accumulate(), step=batch_id+epoch_id*(batch_size))\n",
    "\n",
    "    print(\"epoch_id: {}, batch_id: {}, loss: {}, acc: {}, recall: {}\".format(epoch_id, batch_id+1, loss.numpy(), acc.numpy(), m.accumulate()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
