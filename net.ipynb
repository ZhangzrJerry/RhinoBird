{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, time, os\n",
    "import numpy as np\n",
    "import paddle\n",
    "import pandas as pd\n",
    "import paddle.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from visualdl import LogWriter\n",
    "logwriter = LogWriter(logdir='./runs')\n",
    "# visualdl --logdir ./runs/ --host 0.0.0.0 --port 8040\n",
    "\n",
    "users_df = pd.read_csv('data/csv/users.csv')\n",
    "items_df = pd.read_csv('data/csv/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_scale = 256\n",
    "batch_size = 16384\n",
    "len_users = len(users_df)\n",
    "len_items = len(items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(paddle.io.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        pass\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx][0:2], self.data[idx][2]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.users_emb = nn.Embedding(len_users+1, emb_scale)\n",
    "        self.items_emb = nn.Embedding(len_items+1, emb_scale)\n",
    "        self.user_fc1 = nn.Linear(emb_scale, 128)\n",
    "        self.item_fc1 = nn.Linear(emb_scale, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.cos = nn.CosineSimilarity()\n",
    "        pass\n",
    "    def forward(self, input):\n",
    "        user = self.users_emb(input[:,0])\n",
    "        item = self.items_emb(input[:,1])\n",
    "        user = self.user_fc1(user)\n",
    "        item = self.item_fc1(item)\n",
    "        user = self.relu(user)\n",
    "        item = self.relu(item)\n",
    "        x = self.cos(user, item)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    pass\n",
    "net = Net()\n",
    "optim = paddle.optimizer.Adam(parameters=net.parameters(), learning_rate=0.005, weight_decay=paddle.regularizer.L2Decay(1e-3))\n",
    "m = paddle.metric.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\2023犀牛鸟中学科学人才培养计划\\Flask\\net.ipynb 单元格 5\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_dataset)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     x_data \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     y_data \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss_, train_acc_, eval_loss_, eval_acc_ = [], [], [], []\n",
    "\n",
    "for epoch_id in range(1):\n",
    "\n",
    "    train_loss, train_acc, eval_loss, eval_acc = [], [], [], []\n",
    "\n",
    "    net.train()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(tqdm(train_dataset)):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = net(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        optim.clear_grad()\n",
    "        train_loss.append(loss.numpy())\n",
    "        train_acc.append(acc.numpy())\n",
    "\n",
    "        logwriter.add_scalar(\"train_loss\", value=loss.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"train_acc\", value=acc.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"train_recall\", value=m.accumulate(), step=batch_id+epoch_id*(batch_size))\n",
    "        \n",
    "        if m.accumulate() > 0.3:\n",
    "            break\n",
    "\n",
    "    file_list = os.listdir('data/net/eval/')\n",
    "    file = open('data/net/eval/'+np.random.choice(file_list), 'rb')\n",
    "    train_dataset = paddle.io.DataLoader(Dataset(pickle.load(file)),\n",
    "                                         drop_last=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "    file.close() \n",
    "\n",
    "    net.eval()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(tqdm(train_dataset)):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = net(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "\n",
    "    logwriter.add_scalar(\"eval_loss\", value=np.mean(eval_loss), step=epoch_id)\n",
    "    logwriter.add_scalar(\"eval_acc\", value=np.mean(eval_acc), step=epoch_id)\n",
    "    logwriter.add_scalar(\"eval_recall\", value=m.accumulate(), step=epoch_id)\n",
    "\n",
    "    train_loss_.append(train_loss)\n",
    "    train_acc_.append(train_acc)\n",
    "    eval_loss_.append(eval_loss)\n",
    "    eval_acc_.append(eval_acc)\n",
    "    print(\"epoch_id: {}, batch_id: {}, loss: {}, acc: {}, recall: {}\".format(epoch_id, batch_id+1, loss.numpy(), acc.numpy(), m.accumulate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_id: 0, batch_id: 104, loss: [0.33535033], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 1, batch_id: 104, loss: [0.33551526], acc: [0.9980469], recall: 1.0\n",
      "epoch_id: 2, batch_id: 104, loss: [0.33550274], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 3, batch_id: 104, loss: [0.33559328], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 4, batch_id: 104, loss: [0.3355109], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 5, batch_id: 104, loss: [0.33555275], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 6, batch_id: 104, loss: [0.33550736], acc: [0.9984131], recall: 1.0\n",
      "epoch_id: 7, batch_id: 104, loss: [0.33529878], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 8, batch_id: 104, loss: [0.33524355], acc: [0.9984741], recall: 1.0\n",
      "epoch_id: 9, batch_id: 104, loss: [0.33541608], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 10, batch_id: 104, loss: [0.33567217], acc: [0.9993286], recall: 1.0\n",
      "epoch_id: 11, batch_id: 104, loss: [0.33535877], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 12, batch_id: 104, loss: [0.33580738], acc: [0.99920654], recall: 1.0\n",
      "epoch_id: 13, batch_id: 104, loss: [0.33560538], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 14, batch_id: 104, loss: [0.33570307], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 15, batch_id: 104, loss: [0.33534205], acc: [0.9986572], recall: 1.0\n",
      "epoch_id: 16, batch_id: 104, loss: [0.33556584], acc: [0.9991455], recall: 1.0\n",
      "epoch_id: 17, batch_id: 104, loss: [0.33549014], acc: [0.99884033], recall: 1.0\n",
      "epoch_id: 18, batch_id: 104, loss: [0.33561343], acc: [0.9991455], recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_loss_, train_acc_, eval_loss_, eval_acc_ = [], [], [], []\n",
    "\n",
    "file_list = os.listdir('data/net/train/')\n",
    "\n",
    "for epoch_id, file in enumerate(file_list):\n",
    "    \n",
    "    file = open('data/net/train/'+file, 'rb')\n",
    "    train_dataset = paddle.io.DataLoader(Dataset(pickle.load(file)),\n",
    "                                         drop_last=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "    file.close() \n",
    "\n",
    "    train_loss, train_acc, eval_loss, eval_acc = [], [], [], []\n",
    "    \n",
    "    net.eval()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(train_dataset):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = net(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "\n",
    "    logwriter.add_scalar(\"eval_loss\", value=np.mean(eval_loss), step=epoch_id)\n",
    "    logwriter.add_scalar(\"eval_acc\", value=np.mean(eval_acc), step=epoch_id)\n",
    "    logwriter.add_scalar(\"eval_recall\", value=m.accumulate(), step=epoch_id)\n",
    "\n",
    "    train_loss_.append(train_loss)\n",
    "    train_acc_.append(train_acc)\n",
    "    eval_loss_.append(eval_loss)\n",
    "    eval_acc_.append(eval_acc)\n",
    "    print(\"epoch_id: {}, batch_id: {}, loss: {}, acc: {}, recall: {}\".format(epoch_id, batch_id+1, loss.numpy(), acc.numpy(), m.accumulate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.pkl',\n",
       " '10.pkl',\n",
       " '100.pkl',\n",
       " '11.pkl',\n",
       " '12.pkl',\n",
       " '13.pkl',\n",
       " '14.pkl',\n",
       " '15.pkl',\n",
       " '16.pkl',\n",
       " '17.pkl',\n",
       " '18.pkl',\n",
       " '19.pkl',\n",
       " '2.pkl',\n",
       " '20.pkl',\n",
       " '21.pkl',\n",
       " '22.pkl',\n",
       " '23.pkl',\n",
       " '24.pkl',\n",
       " '25.pkl',\n",
       " '26.pkl',\n",
       " '27.pkl',\n",
       " '28.pkl',\n",
       " '29.pkl',\n",
       " '3.pkl',\n",
       " '30.pkl',\n",
       " '31.pkl',\n",
       " '32.pkl',\n",
       " '33.pkl',\n",
       " '34.pkl',\n",
       " '35.pkl',\n",
       " '36.pkl',\n",
       " '37.pkl',\n",
       " '38.pkl',\n",
       " '39.pkl',\n",
       " '4.pkl',\n",
       " '40.pkl',\n",
       " '41.pkl',\n",
       " '42.pkl',\n",
       " '43.pkl',\n",
       " '44.pkl',\n",
       " '45.pkl',\n",
       " '46.pkl',\n",
       " '47.pkl',\n",
       " '48.pkl',\n",
       " '49.pkl',\n",
       " '5.pkl',\n",
       " '50.pkl',\n",
       " '51.pkl',\n",
       " '52.pkl',\n",
       " '53.pkl',\n",
       " '54.pkl',\n",
       " '55.pkl',\n",
       " '56.pkl',\n",
       " '57.pkl',\n",
       " '58.pkl',\n",
       " '59.pkl',\n",
       " '6.pkl',\n",
       " '60.pkl',\n",
       " '61.pkl',\n",
       " '62.pkl',\n",
       " '63.pkl',\n",
       " '64.pkl',\n",
       " '65.pkl',\n",
       " '66.pkl',\n",
       " '67.pkl',\n",
       " '68.pkl',\n",
       " '69.pkl',\n",
       " '7.pkl',\n",
       " '70.pkl',\n",
       " '71.pkl',\n",
       " '72.pkl',\n",
       " '73.pkl',\n",
       " '74.pkl',\n",
       " '75.pkl',\n",
       " '76.pkl',\n",
       " '77.pkl',\n",
       " '78.pkl',\n",
       " '79.pkl',\n",
       " '8.pkl',\n",
       " '80.pkl',\n",
       " '81.pkl',\n",
       " '82.pkl',\n",
       " '83.pkl',\n",
       " '84.pkl',\n",
       " '85.pkl',\n",
       " '86.pkl',\n",
       " '87.pkl',\n",
       " '88.pkl',\n",
       " '89.pkl',\n",
       " '9.pkl',\n",
       " '90.pkl',\n",
       " '91.pkl',\n",
       " '92.pkl',\n",
       " '93.pkl',\n",
       " '94.pkl',\n",
       " '95.pkl',\n",
       " '96.pkl',\n",
       " '97.pkl',\n",
       " '98.pkl',\n",
       " '99.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42803200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) * batch_size * len(file_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
