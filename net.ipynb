{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, time, os\n",
    "import numpy as np\n",
    "import paddle\n",
    "import pandas as pd\n",
    "import paddle.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from visualdl import LogWriter\n",
    "logwriter = LogWriter(logdir='./runs')\n",
    "# visualdl --logdir ./runs/ --host 0.0.0.0 --port 8040\n",
    "\n",
    "users_df = pd.read_csv('data/csv/users.csv')\n",
    "items_df = pd.read_csv('data/csv/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_scale = 256\n",
    "batch_size = 16384\n",
    "len_users = len(users_df)\n",
    "len_items = len(items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(paddle.io.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        pass\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx][0:2], self.data[idx][2]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.users_emb = nn.Embedding(len_users+1, emb_scale)\n",
    "        self.items_emb = nn.Embedding(len_items+1, emb_scale)\n",
    "        self.user_fc1 = nn.Linear(emb_scale, 128)\n",
    "        self.item_fc1 = nn.Linear(emb_scale, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.cos = nn.CosineSimilarity()\n",
    "        pass\n",
    "    def forward(self, input):\n",
    "        user = self.users_emb(input[:,0])\n",
    "        item = self.items_emb(input[:,1])\n",
    "        user = self.user_fc1(user)\n",
    "        item = self.item_fc1(item)\n",
    "        user = self.relu(user)\n",
    "        item = self.relu(item)\n",
    "        x = self.cos(user, item)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    pass\n",
    "net = Net()\n",
    "optim = paddle.optimizer.Adam(parameters=net.parameters(), learning_rate=0.005, weight_decay=paddle.regularizer.L2Decay(1e-3))\n",
    "m = paddle.metric.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\2023犀牛鸟中学科学人才培养计划\\Flask\\net.ipynb 单元格 5\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_dataset)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     x_data \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/net.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     y_data \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss_, train_acc_, eval_loss_, eval_acc_ = [], [], [], []\n",
    "\n",
    "for epoch_id in range(1):\n",
    "\n",
    "    train_loss, train_acc, eval_loss, eval_acc = [], [], [], []\n",
    "\n",
    "    net.train()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(tqdm(train_dataset)):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = net(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        optim.clear_grad()\n",
    "        train_loss.append(loss.numpy())\n",
    "        train_acc.append(acc.numpy())\n",
    "\n",
    "        logwriter.add_scalar(\"train_loss\", value=loss.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"train_acc\", value=acc.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"train_recall\", value=m.accumulate(), step=batch_id+epoch_id*(batch_size))\n",
    "        \n",
    "        if m.accumulate() > 0.3:\n",
    "            break\n",
    "\n",
    "    file_list = os.listdir('data/net/eval/')\n",
    "    file = open('data/net/eval/'+np.random.choice(file_list), 'rb')\n",
    "    train_dataset = paddle.io.DataLoader(Dataset(pickle.load(file)),\n",
    "                                         drop_last=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "    file.close() \n",
    "\n",
    "    net.eval()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(tqdm(train_dataset)):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = net(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "\n",
    "    logwriter.add_scalar(\"eval_loss\", value=np.mean(eval_loss), step=epoch_id)\n",
    "    logwriter.add_scalar(\"eval_acc\", value=np.mean(eval_acc), step=epoch_id)\n",
    "    logwriter.add_scalar(\"eval_recall\", value=m.accumulate(), step=epoch_id)\n",
    "\n",
    "    train_loss_.append(train_loss)\n",
    "    train_acc_.append(train_acc)\n",
    "    eval_loss_.append(eval_loss)\n",
    "    eval_acc_.append(eval_acc)\n",
    "    print(\"epoch_id: {}, batch_id: {}, loss: {}, acc: {}, recall: {}\".format(epoch_id, batch_id+1, loss.numpy(), acc.numpy(), m.accumulate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_id: 0, batch_id: 104, loss: [0.33535033], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 1, batch_id: 104, loss: [0.33551526], acc: [0.9980469], recall: 1.0\n",
      "epoch_id: 2, batch_id: 104, loss: [0.33550274], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 3, batch_id: 104, loss: [0.33559328], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 4, batch_id: 104, loss: [0.3355109], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 5, batch_id: 104, loss: [0.33555275], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 6, batch_id: 104, loss: [0.33550736], acc: [0.9984131], recall: 1.0\n",
      "epoch_id: 7, batch_id: 104, loss: [0.33529878], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 8, batch_id: 104, loss: [0.33524355], acc: [0.9984741], recall: 1.0\n",
      "epoch_id: 9, batch_id: 104, loss: [0.33541608], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 10, batch_id: 104, loss: [0.33567217], acc: [0.9993286], recall: 1.0\n",
      "epoch_id: 11, batch_id: 104, loss: [0.33535877], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 12, batch_id: 104, loss: [0.33580738], acc: [0.99920654], recall: 1.0\n",
      "epoch_id: 13, batch_id: 104, loss: [0.33560538], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 14, batch_id: 104, loss: [0.33570307], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 15, batch_id: 104, loss: [0.33534205], acc: [0.9986572], recall: 1.0\n",
      "epoch_id: 16, batch_id: 104, loss: [0.33556584], acc: [0.9991455], recall: 1.0\n",
      "epoch_id: 17, batch_id: 104, loss: [0.33549014], acc: [0.99884033], recall: 1.0\n",
      "epoch_id: 18, batch_id: 104, loss: [0.33561343], acc: [0.9991455], recall: 1.0\n",
      "epoch_id: 19, batch_id: 104, loss: [0.33584625], acc: [0.99902344], recall: 1.0\n",
      "epoch_id: 20, batch_id: 104, loss: [0.33530557], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 21, batch_id: 104, loss: [0.3353763], acc: [0.99890137], recall: 1.0\n",
      "epoch_id: 22, batch_id: 104, loss: [0.33520097], acc: [0.99884033], recall: 1.0\n",
      "epoch_id: 23, batch_id: 104, loss: [0.33554077], acc: [0.99853516], recall: 1.0\n",
      "epoch_id: 24, batch_id: 104, loss: [0.33567703], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 25, batch_id: 104, loss: [0.33548406], acc: [0.99816895], recall: 1.0\n",
      "epoch_id: 26, batch_id: 104, loss: [0.33566874], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 27, batch_id: 104, loss: [0.33555], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 28, batch_id: 104, loss: [0.33531487], acc: [0.9981079], recall: 1.0\n",
      "epoch_id: 29, batch_id: 104, loss: [0.33542907], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 30, batch_id: 104, loss: [0.3352198], acc: [0.99884033], recall: 1.0\n",
      "epoch_id: 31, batch_id: 104, loss: [0.33540437], acc: [0.998291], recall: 1.0\n",
      "epoch_id: 32, batch_id: 104, loss: [0.33557254], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 33, batch_id: 104, loss: [0.33567208], acc: [0.99920654], recall: 1.0\n",
      "epoch_id: 34, batch_id: 104, loss: [0.33555812], acc: [0.99890137], recall: 1.0\n",
      "epoch_id: 35, batch_id: 104, loss: [0.33564812], acc: [0.99853516], recall: 1.0\n",
      "epoch_id: 36, batch_id: 104, loss: [0.33574644], acc: [0.99890137], recall: 1.0\n",
      "epoch_id: 37, batch_id: 104, loss: [0.33564997], acc: [0.9984131], recall: 1.0\n",
      "epoch_id: 38, batch_id: 104, loss: [0.33548295], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 39, batch_id: 104, loss: [0.335518], acc: [0.9985962], recall: 1.0\n",
      "epoch_id: 40, batch_id: 104, loss: [0.335652], acc: [0.99890137], recall: 1.0\n",
      "epoch_id: 41, batch_id: 104, loss: [0.33535725], acc: [0.99835205], recall: 1.0\n",
      "epoch_id: 42, batch_id: 104, loss: [0.33566034], acc: [0.99902344], recall: 1.0\n",
      "epoch_id: 43, batch_id: 104, loss: [0.33539608], acc: [0.99835205], recall: 1.0\n",
      "epoch_id: 44, batch_id: 104, loss: [0.3355594], acc: [0.9993286], recall: 1.0\n",
      "epoch_id: 45, batch_id: 104, loss: [0.33575273], acc: [0.99902344], recall: 1.0\n",
      "epoch_id: 46, batch_id: 104, loss: [0.33571762], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 47, batch_id: 104, loss: [0.33535627], acc: [0.99890137], recall: 1.0\n",
      "epoch_id: 48, batch_id: 104, loss: [0.33554572], acc: [0.9986572], recall: 1.0\n",
      "epoch_id: 49, batch_id: 104, loss: [0.33551142], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 50, batch_id: 104, loss: [0.33567283], acc: [0.99920654], recall: 1.0\n",
      "epoch_id: 51, batch_id: 104, loss: [0.3356127], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 52, batch_id: 104, loss: [0.33556855], acc: [0.99835205], recall: 1.0\n",
      "epoch_id: 53, batch_id: 104, loss: [0.3353102], acc: [0.9985962], recall: 1.0\n",
      "epoch_id: 54, batch_id: 104, loss: [0.3354333], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 55, batch_id: 104, loss: [0.33568498], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 56, batch_id: 104, loss: [0.33589995], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 57, batch_id: 104, loss: [0.33562845], acc: [0.99853516], recall: 1.0\n",
      "epoch_id: 58, batch_id: 104, loss: [0.3354025], acc: [0.99853516], recall: 1.0\n",
      "epoch_id: 59, batch_id: 104, loss: [0.335818], acc: [0.99902344], recall: 1.0\n",
      "epoch_id: 60, batch_id: 104, loss: [0.33565432], acc: [0.9991455], recall: 1.0\n",
      "epoch_id: 61, batch_id: 104, loss: [0.33565295], acc: [0.9984131], recall: 1.0\n",
      "epoch_id: 62, batch_id: 104, loss: [0.33560625], acc: [0.99884033], recall: 1.0\n",
      "epoch_id: 63, batch_id: 104, loss: [0.33542347], acc: [0.99884033], recall: 1.0\n",
      "epoch_id: 64, batch_id: 104, loss: [0.3355391], acc: [0.9992676], recall: 1.0\n",
      "epoch_id: 65, batch_id: 104, loss: [0.3354714], acc: [0.99902344], recall: 1.0\n",
      "epoch_id: 66, batch_id: 104, loss: [0.33536458], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 67, batch_id: 104, loss: [0.33548895], acc: [0.99853516], recall: 1.0\n",
      "epoch_id: 68, batch_id: 104, loss: [0.3357725], acc: [0.9991455], recall: 1.0\n",
      "epoch_id: 69, batch_id: 104, loss: [0.3355416], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 70, batch_id: 104, loss: [0.33561915], acc: [0.9992676], recall: 1.0\n",
      "epoch_id: 71, batch_id: 104, loss: [0.33539575], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 72, batch_id: 104, loss: [0.33540443], acc: [0.9984741], recall: 1.0\n",
      "epoch_id: 73, batch_id: 104, loss: [0.33529195], acc: [0.9984741], recall: 1.0\n",
      "epoch_id: 74, batch_id: 104, loss: [0.335465], acc: [0.9984131], recall: 1.0\n",
      "epoch_id: 75, batch_id: 104, loss: [0.33569282], acc: [0.9986572], recall: 1.0\n",
      "epoch_id: 76, batch_id: 104, loss: [0.33544832], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 77, batch_id: 104, loss: [0.33566266], acc: [0.99890137], recall: 1.0\n",
      "epoch_id: 78, batch_id: 104, loss: [0.3355888], acc: [0.9981079], recall: 1.0\n",
      "epoch_id: 79, batch_id: 104, loss: [0.3354771], acc: [0.9985962], recall: 1.0\n",
      "epoch_id: 80, batch_id: 104, loss: [0.33583933], acc: [0.9986572], recall: 1.0\n",
      "epoch_id: 81, batch_id: 104, loss: [0.33533686], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 82, batch_id: 104, loss: [0.33525178], acc: [0.9984741], recall: 1.0\n",
      "epoch_id: 83, batch_id: 104, loss: [0.33549476], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 84, batch_id: 104, loss: [0.33535013], acc: [0.99871826], recall: 1.0\n",
      "epoch_id: 85, batch_id: 104, loss: [0.33598527], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 86, batch_id: 104, loss: [0.33576047], acc: [0.99890137], recall: 1.0\n",
      "epoch_id: 87, batch_id: 104, loss: [0.33570555], acc: [0.99920654], recall: 1.0\n",
      "epoch_id: 88, batch_id: 104, loss: [0.33574665], acc: [0.9986572], recall: 1.0\n",
      "epoch_id: 89, batch_id: 104, loss: [0.335198], acc: [0.9986572], recall: 1.0\n",
      "epoch_id: 90, batch_id: 104, loss: [0.3355615], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 91, batch_id: 104, loss: [0.3355533], acc: [0.9987793], recall: 1.0\n",
      "epoch_id: 92, batch_id: 104, loss: [0.33554298], acc: [0.99920654], recall: 1.0\n",
      "epoch_id: 93, batch_id: 104, loss: [0.3357709], acc: [0.9985962], recall: 1.0\n",
      "epoch_id: 94, batch_id: 104, loss: [0.3354478], acc: [0.99853516], recall: 1.0\n",
      "epoch_id: 95, batch_id: 104, loss: [0.33535755], acc: [0.99884033], recall: 1.0\n",
      "epoch_id: 96, batch_id: 104, loss: [0.33552504], acc: [0.9985962], recall: 1.0\n",
      "epoch_id: 97, batch_id: 104, loss: [0.33540663], acc: [0.9990845], recall: 1.0\n",
      "epoch_id: 98, batch_id: 104, loss: [0.33557987], acc: [0.9989624], recall: 1.0\n",
      "epoch_id: 99, batch_id: 104, loss: [0.33545196], acc: [0.99902344], recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_loss_, train_acc_, eval_loss_, eval_acc_ = [], [], [], []\n",
    "\n",
    "file_list = os.listdir('data/net/train/')\n",
    "\n",
    "for epoch_id, file in enumerate(file_list):\n",
    "    \n",
    "    file = open('data/net/train/'+file, 'rb')\n",
    "    train_dataset = paddle.io.DataLoader(Dataset(pickle.load(file)),\n",
    "                                         drop_last=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "    file.close() \n",
    "\n",
    "    train_loss, train_acc, eval_loss, eval_acc = [], [], [], []\n",
    "    \n",
    "    net.eval()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(train_dataset):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = net(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "\n",
    "    logwriter.add_scalar(\"eval_loss\", value=np.mean(eval_loss), step=epoch_id)\n",
    "    logwriter.add_scalar(\"eval_acc\", value=np.mean(eval_acc), step=epoch_id)\n",
    "    logwriter.add_scalar(\"eval_recall\", value=m.accumulate(), step=epoch_id)\n",
    "\n",
    "    train_loss_.append(train_loss)\n",
    "    train_acc_.append(train_acc)\n",
    "    eval_loss_.append(eval_loss)\n",
    "    eval_acc_.append(eval_acc)\n",
    "    print(\"epoch_id: {}, batch_id: {}, loss: {}, acc: {}, recall: {}\".format(epoch_id, batch_id+1, loss.numpy(), acc.numpy(), m.accumulate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.pkl',\n",
       " '10.pkl',\n",
       " '100.pkl',\n",
       " '11.pkl',\n",
       " '12.pkl',\n",
       " '13.pkl',\n",
       " '14.pkl',\n",
       " '15.pkl',\n",
       " '16.pkl',\n",
       " '17.pkl',\n",
       " '18.pkl',\n",
       " '19.pkl',\n",
       " '2.pkl',\n",
       " '20.pkl',\n",
       " '21.pkl',\n",
       " '22.pkl',\n",
       " '23.pkl',\n",
       " '24.pkl',\n",
       " '25.pkl',\n",
       " '26.pkl',\n",
       " '27.pkl',\n",
       " '28.pkl',\n",
       " '29.pkl',\n",
       " '3.pkl',\n",
       " '30.pkl',\n",
       " '31.pkl',\n",
       " '32.pkl',\n",
       " '33.pkl',\n",
       " '34.pkl',\n",
       " '35.pkl',\n",
       " '36.pkl',\n",
       " '37.pkl',\n",
       " '38.pkl',\n",
       " '39.pkl',\n",
       " '4.pkl',\n",
       " '40.pkl',\n",
       " '41.pkl',\n",
       " '42.pkl',\n",
       " '43.pkl',\n",
       " '44.pkl',\n",
       " '45.pkl',\n",
       " '46.pkl',\n",
       " '47.pkl',\n",
       " '48.pkl',\n",
       " '49.pkl',\n",
       " '5.pkl',\n",
       " '50.pkl',\n",
       " '51.pkl',\n",
       " '52.pkl',\n",
       " '53.pkl',\n",
       " '54.pkl',\n",
       " '55.pkl',\n",
       " '56.pkl',\n",
       " '57.pkl',\n",
       " '58.pkl',\n",
       " '59.pkl',\n",
       " '6.pkl',\n",
       " '60.pkl',\n",
       " '61.pkl',\n",
       " '62.pkl',\n",
       " '63.pkl',\n",
       " '64.pkl',\n",
       " '65.pkl',\n",
       " '66.pkl',\n",
       " '67.pkl',\n",
       " '68.pkl',\n",
       " '69.pkl',\n",
       " '7.pkl',\n",
       " '70.pkl',\n",
       " '71.pkl',\n",
       " '72.pkl',\n",
       " '73.pkl',\n",
       " '74.pkl',\n",
       " '75.pkl',\n",
       " '76.pkl',\n",
       " '77.pkl',\n",
       " '78.pkl',\n",
       " '79.pkl',\n",
       " '8.pkl',\n",
       " '80.pkl',\n",
       " '81.pkl',\n",
       " '82.pkl',\n",
       " '83.pkl',\n",
       " '84.pkl',\n",
       " '85.pkl',\n",
       " '86.pkl',\n",
       " '87.pkl',\n",
       " '88.pkl',\n",
       " '89.pkl',\n",
       " '9.pkl',\n",
       " '90.pkl',\n",
       " '91.pkl',\n",
       " '92.pkl',\n",
       " '93.pkl',\n",
       " '94.pkl',\n",
       " '95.pkl',\n",
       " '96.pkl',\n",
       " '97.pkl',\n",
       " '98.pkl',\n",
       " '99.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42803200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) * batch_size * len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle.save(net.state_dict(), 'data/model.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.set_state_dict(paddle.load('data/model.pdparams'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('users_emb.weight',\n",
       "              Parameter containing:\n",
       "              Tensor(shape=[12119, 256], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
       "                     [[ 0.01226373, -0.00018846,  0.01930048, ..., -0.00143591,\n",
       "                       -0.00942702,  0.00551308],\n",
       "                      [ 0.01507964,  0.01957043, -0.00743642, ...,  0.01419000,\n",
       "                        0.00617457,  0.00221456],\n",
       "                      [ 0.01868310, -0.01385227, -0.02084335, ...,  0.00755191,\n",
       "                       -0.00677125,  0.00990534],\n",
       "                      ...,\n",
       "                      [-0.00433739, -0.01126241, -0.01520206, ...,  0.01855347,\n",
       "                        0.01137436,  0.01814571],\n",
       "                      [-0.00794235, -0.00775500,  0.01469941, ..., -0.00523128,\n",
       "                        0.01908569, -0.01021772],\n",
       "                      [-0.00430771, -0.00947088,  0.01025717, ...,  0.00727685,\n",
       "                       -0.00015765, -0.01571073]])),\n",
       "             ('items_emb.weight',\n",
       "              Parameter containing:\n",
       "              Tensor(shape=[24017, 256], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
       "                     [[ 0.01117150,  0.00431858,  0.00853882, ..., -0.00159990,\n",
       "                       -0.00107245,  0.01424450],\n",
       "                      [ 0.00504405,  0.01472395,  0.01529999, ..., -0.01263597,\n",
       "                        0.00089404, -0.00948242],\n",
       "                      [ 0.01292130,  0.00845965,  0.00868505, ...,  0.00116951,\n",
       "                        0.01400365,  0.01239213],\n",
       "                      ...,\n",
       "                      [-0.00570277, -0.00915839, -0.00564914, ...,  0.00674548,\n",
       "                       -0.01483308, -0.00643648],\n",
       "                      [-0.00819785, -0.00439462,  0.01304215, ...,  0.00758851,\n",
       "                       -0.00177551, -0.00977818],\n",
       "                      [-0.01395038, -0.01440926,  0.00991888, ..., -0.00432430,\n",
       "                       -0.00910527, -0.00007028]])),\n",
       "             ('user_fc1.weight',\n",
       "              Parameter containing:\n",
       "              Tensor(shape=[256, 128], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
       "                     [[ 0.11875194,  0.06294845, -0.05095437, ..., -0.07125077,\n",
       "                        0.02880901, -0.07167991],\n",
       "                      [-0.09502131,  0.09173100,  0.11444058, ..., -0.07839414,\n",
       "                       -0.08656663,  0.10500668],\n",
       "                      [-0.07775322,  0.00812404,  0.03820916, ..., -0.02334306,\n",
       "                       -0.02367877,  0.08545586],\n",
       "                      ...,\n",
       "                      [ 0.09322438, -0.08004816,  0.08787967, ..., -0.11176244,\n",
       "                       -0.11634722,  0.08762094],\n",
       "                      [-0.11250900,  0.06356697, -0.07128655, ...,  0.10826838,\n",
       "                        0.05225590, -0.02883913],\n",
       "                      [ 0.02404308, -0.11764062, -0.11506088, ..., -0.12149862,\n",
       "                        0.04606190, -0.09559497]])),\n",
       "             ('user_fc1.bias',\n",
       "              Parameter containing:\n",
       "              Tensor(shape=[128], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
       "                     [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0.])),\n",
       "             ('item_fc1.weight',\n",
       "              Parameter containing:\n",
       "              Tensor(shape=[256, 128], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
       "                     [[ 0.07044779,  0.11296874, -0.01749417, ...,  0.04382247,\n",
       "                        0.12005928,  0.00617462],\n",
       "                      [-0.09886562, -0.07281269,  0.04533647, ...,  0.02529296,\n",
       "                       -0.07559395, -0.03951507],\n",
       "                      [-0.04734123, -0.03725845,  0.00957292, ...,  0.08220007,\n",
       "                       -0.10634471, -0.08130962],\n",
       "                      ...,\n",
       "                      [-0.09362249, -0.10728177,  0.00983381, ...,  0.01728842,\n",
       "                        0.03912559,  0.00929654],\n",
       "                      [-0.03488501, -0.02588204, -0.00937191, ..., -0.02445180,\n",
       "                        0.00632605, -0.03366192],\n",
       "                      [ 0.08009489,  0.10895248,  0.11016475, ..., -0.03043228,\n",
       "                       -0.08734243,  0.09813988]])),\n",
       "             ('item_fc1.bias',\n",
       "              Parameter containing:\n",
       "              Tensor(shape=[128], dtype=float32, place=Place(cpu), stop_gradient=False,\n",
       "                     [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0.]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
