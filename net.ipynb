{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, time, os\n",
    "import numpy as np\n",
    "import paddle\n",
    "import pandas as pd\n",
    "import paddle.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from visualdl import LogWriter\n",
    "logwriter = LogWriter(logdir='./runs')\n",
    "# visualdl --logdir ./runs/ --host 0.0.0.0 --port 8040\n",
    "\n",
    "users_df = pd.read_csv('data/csv/users.csv')\n",
    "items_df = pd.read_csv('data/csv/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_scale = 64\n",
    "batch_size = 2048\n",
    "len_users = len(users_df)\n",
    "len_items = len(items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(paddle.io.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        pass\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx][0:2], self.data[idx][2]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.users_emb = nn.Embedding(len_users+1, emb_scale)\n",
    "        self.items_emb = nn.Embedding(len_items+1, emb_scale)\n",
    "        self.fc1 = nn.Linear(2 * emb_scale, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        pass\n",
    "    def forward(self, input):\n",
    "        user = self.users_emb(input[:,0])\n",
    "        item = self.items_emb(input[:,1])\n",
    "        x = paddle.concat([user, item], axis=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    pass\n",
    "net = Net()\n",
    "optim = paddle.optimizer.Adam(parameters=net.parameters(), learning_rate=0.005, weight_decay=paddle.regularizer.L2Decay(1e+2))\n",
    "m = paddle.metric.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 105/209 [06:12<06:09,  3.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\2023犀牛鸟中学科学人才培养计划\\Flask\\DSSM.ipynb 单元格 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m m\u001b[39m.\u001b[39mupdate(y_pred, y_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m optim\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m optim\u001b[39m.\u001b[39mclear_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/2023%E7%8A%80%E7%89%9B%E9%B8%9F%E4%B8%AD%E5%AD%A6%E7%A7%91%E5%AD%A6%E4%BA%BA%E6%89%8D%E5%9F%B9%E5%85%BB%E8%AE%A1%E5%88%92/Flask/DSSM.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\paddle\\fluid\\dygraph\\base.py:335\u001b[0m, in \u001b[0;36mno_grad.<locals>.__impl__\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39m@decorator\u001b[39m\u001b[39m.\u001b[39mdecorator\n\u001b[0;32m    333\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__impl__\u001b[39m(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    334\u001b[0m     \u001b[39mwith\u001b[39;00m _switch_tracer_mode_guard_(is_train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 335\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\paddle\\fluid\\wrapped_decorator.py:25\u001b[0m, in \u001b[0;36mwrap_decorator.<locals>.__impl__\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m@decorator\u001b[39m\u001b[39m.\u001b[39mdecorator\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__impl__\u001b[39m(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     24\u001b[0m     wrapped_func \u001b[39m=\u001b[39m decorator_func(func)\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\paddle\\fluid\\framework.py:462\u001b[0m, in \u001b[0;36m_non_static_only_.<locals>.__impl__\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdygraph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m in_declarative_mode\n\u001b[0;32m    458\u001b[0m \u001b[39massert\u001b[39;00m in_dygraph_mode() \u001b[39mor\u001b[39;00m in_declarative_mode(), (\n\u001b[0;32m    459\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mWe only support \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in dynamic graph mode, please call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpaddle.disable_static()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to enter dynamic graph mode.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m     \u001b[39m%\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    461\u001b[0m )\n\u001b[1;32m--> 462\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\paddle\\optimizer\\adam.py:446\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    442\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mAdam don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support weight_decay with sparse parameters, please set it to None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    443\u001b[0m                     )\n\u001b[0;32m    444\u001b[0m             params_grads\u001b[39m.\u001b[39mappend((param, grad_var))\n\u001b[1;32m--> 446\u001b[0m     optimize_ops \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_optimize(\n\u001b[0;32m    447\u001b[0m         loss\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    448\u001b[0m         startup_program\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    449\u001b[0m         params_grads\u001b[39m=\u001b[39;49mparams_grads,\n\u001b[0;32m    450\u001b[0m         param_group_idx\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[39m# optimize parameters in groups\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[39mfor\u001b[39;00m idx, param_group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_param_groups):\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\paddle\\optimizer\\optimizer.py:1243\u001b[0m, in \u001b[0;36mOptimizer._apply_optimize\u001b[1;34m(self, loss, startup_program, params_grads, param_group_idx)\u001b[0m\n\u001b[0;32m   1236\u001b[0m                 params_grads[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m grad_clip(\n\u001b[0;32m   1237\u001b[0m                     params_grads[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m   1238\u001b[0m                 )\n\u001b[0;32m   1240\u001b[0m             params_grads[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend_regularization_ops(\n\u001b[0;32m   1241\u001b[0m                 params_grads[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregularization\n\u001b[0;32m   1242\u001b[0m             )\n\u001b[1;32m-> 1243\u001b[0m         optimize_ops \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_optimization_pass(\n\u001b[0;32m   1244\u001b[0m             params_grads, param_group_idx\u001b[39m=\u001b[39;49mparam_group_idx\n\u001b[0;32m   1245\u001b[0m         )\n\u001b[0;32m   1246\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[39massert\u001b[39;00m param_group_idx \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\paddle\\optimizer\\optimizer.py:1026\u001b[0m, in \u001b[0;36mOptimizer._create_optimization_pass\u001b[1;34m(self, parameters_and_grads, param_group_idx)\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m         \u001b[39mif\u001b[39;00m param_and_grad[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstop_gradient \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m-> 1026\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_append_optimize_op(\n\u001b[0;32m   1027\u001b[0m                 target_block, param_and_grad\n\u001b[0;32m   1028\u001b[0m             )\n\u001b[0;32m   1029\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1030\u001b[0m     \u001b[39mfor\u001b[39;00m param_and_grad \u001b[39min\u001b[39;00m parameters_and_grads[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32md:\\program files\\anaconda\\envs\\recommendation-service\\Lib\\site-packages\\paddle\\optimizer\\adam.py:321\u001b[0m, in \u001b[0;36mAdam._append_optimize_op\u001b[1;34m(self, block, param_and_grad)\u001b[0m\n\u001b[0;32m    310\u001b[0m     _beta1 \u001b[39m=\u001b[39m (\n\u001b[0;32m    311\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_beta1\n\u001b[0;32m    312\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_beta1, Variable)\n\u001b[0;32m    313\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_beta1\u001b[39m.\u001b[39mitem(\u001b[39m0\u001b[39m)\n\u001b[0;32m    314\u001b[0m     )\n\u001b[0;32m    315\u001b[0m     _beta2 \u001b[39m=\u001b[39m (\n\u001b[0;32m    316\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_beta2\n\u001b[0;32m    317\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_beta2, Variable)\n\u001b[0;32m    318\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_beta2\u001b[39m.\u001b[39mitem(\u001b[39m0\u001b[39m)\n\u001b[0;32m    319\u001b[0m     )\n\u001b[1;32m--> 321\u001b[0m     _, _, _, _, _, _ \u001b[39m=\u001b[39m _C_ops\u001b[39m.\u001b[39;49madam_(\n\u001b[0;32m    322\u001b[0m         param_and_grad[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m    323\u001b[0m         param_and_grad[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m    324\u001b[0m         lr,\n\u001b[0;32m    325\u001b[0m         moment1,\n\u001b[0;32m    326\u001b[0m         moment2,\n\u001b[0;32m    327\u001b[0m         beta1_pow_acc,\n\u001b[0;32m    328\u001b[0m         beta2_pow_acc,\n\u001b[0;32m    329\u001b[0m         master_weight,\n\u001b[0;32m    330\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    331\u001b[0m         _beta1,\n\u001b[0;32m    332\u001b[0m         _beta2,\n\u001b[0;32m    333\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_epsilon,\n\u001b[0;32m    334\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_mode,\n\u001b[0;32m    335\u001b[0m         \u001b[39m1000\u001b[39;49m,\n\u001b[0;32m    336\u001b[0m         find_master,\n\u001b[0;32m    337\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    338\u001b[0m     )\n\u001b[0;32m    340\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_, train_acc_, eval_loss_, eval_acc_ = [], [], [], []\n",
    "\n",
    "for epoch_id in range(10):\n",
    "\n",
    "    train_loss, train_acc, eval_loss, eval_acc = [], [], [], []\n",
    "\n",
    "    file_list = os.listdir('data/net/train/')\n",
    "    file = open('data/net/train/'+np.random.choice(file_list), 'rb')\n",
    "    train_dataset = paddle.io.DataLoader(Dataset(pickle.load(file)),\n",
    "                                         drop_last=True,\n",
    "                                         batch_size=batch_size)\n",
    "    file.close()    \n",
    "\n",
    "    net.train()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(tqdm(train_dataset)):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = net(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        optim.clear_grad()\n",
    "        train_loss.append(loss.numpy())\n",
    "        train_acc.append(acc.numpy())\n",
    "\n",
    "        logwriter.add_scalar(\"train_loss\", value=loss.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"train_acc\", value=acc.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"train_recall\", value=m.accumulate(), step=batch_id+epoch_id*(batch_size))\n",
    "\n",
    "    file_list = os.listdir('data/net/eval/')\n",
    "    file = open('data/net/eval/'+np.random.choice(file_list), 'rb')\n",
    "    train_dataset = paddle.io.DataLoader(Dataset(pickle.load(file)),\n",
    "                                         drop_last=True,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "    file.close() \n",
    "\n",
    "    net.eval()\n",
    "    m.reset()\n",
    "    for batch_id, data in enumerate(tqdm(train_dataset)):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        x_data = paddle.cast(x_data, dtype='int32')\n",
    "\n",
    "        y_pred = net(x_data)\n",
    "        loss = nn.functional.mse_loss(y_pred, paddle.cast(y_data, dtype='float32'))\n",
    "        acc = paddle.static.accuracy(paddle.reshape(y_pred, (batch_size, 1)), paddle.reshape(paddle.cast(y_data, dtype='int64'), (batch_size, 1)))\n",
    "        m.update(y_pred, y_data)\n",
    "\n",
    "        logwriter.add_scalar(\"eval_loss\", value=loss.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"eval_acc\", value=acc.numpy(), step=batch_id+epoch_id*(batch_size))\n",
    "        logwriter.add_scalar(\"eval_recall\", value=m.accumulate(), step=batch_id+epoch_id*(batch_size))\n",
    "\n",
    "    print(\"epoch_id: {}, batch_id: {}, loss: {}, acc: {}, recall: {}\".format(epoch_id, batch_id+1, loss.numpy(), acc.numpy(), m.accumulate()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
